{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_PEGASUS_pretrain_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2LONgCSHkKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target\n",
        "target = 'horse'\n",
        "\n",
        "# hyper params\n",
        "EPOCHS = (1000, 1000, 1000, 700, 400, 400)\n",
        "BATCH_SIZES = (64, 64, 64, 32, 16, 8)\n",
        "initial_scale = 1.\n",
        "GPU = 0\n",
        "\n",
        "# extension params\n",
        "log_interval = 10\n",
        "display_interval = 100\n",
        "tweet_interval = 100\n",
        "snapshot_interval = 100\n",
        "\n",
        "# model params\n",
        "sa_gamma = 1\n",
        "gen_noise = 5e-2\n",
        "SCALEUP_ALPHA = 0.5\n",
        "START = 0\n",
        "IMG_SIZE = 256\n",
        "LATENT_SIZE = 256\n",
        "\n",
        "# learning controller\n",
        "learning_rate = 1e-4\n",
        "grad_clip = None\n",
        "gen_weight_decay = 0\n",
        "dis_weight_decay = 0\n",
        "sa_endpoint = 500\n",
        "sg_endpoint = 200\n",
        "\n",
        "# file names\n",
        "load_weight = None\n",
        "\n",
        "mount = '.'\n",
        "OUT = '{}/Drive_sync/result/'.format(mount)\n",
        "dataroot = '{}/Drive_sync/picture/torch_dataset'.format(mount)\n",
        "\n",
        "gen_name = '{}_gen'.format(target)\n",
        "dis_name = '{}_dis'.format(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "taibgWsxewAT",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import io\n",
        "import uuid\n",
        "import tweepy\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import spectral_norm, clip_grad_norm_\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import twitter_api_key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sMBmUGbfmmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian(size):\n",
        "    return torch.normal(torch.zeros(size), torch.ones(size))\n",
        "\n",
        "def zeropad(x, ch):\n",
        "    return F.pad(x, (0, 0, 0, 0, 0, ch-x.size(1), 0, 0))\n",
        "\n",
        "def gap(x):\n",
        "    return F.avg_pooling2d(x, x.size()[-2:])\n",
        "\n",
        "def noise_injection(x, k):\n",
        "    return torch.normal(x, instance_var(x)*k)\n",
        "\n",
        "def instance_var(x):\n",
        "    _shape = x.size()\n",
        "    _x = x.view(_shape[0], _shape[1], -1)\n",
        "    _x = torch.var(_x, dim=2)\n",
        "    _x = _x.view(*_x.size(), 1, 1)\n",
        "    _x = _x.expand(*_shape)\n",
        "    return _x\n",
        "\n",
        "def layer_shuffle(x):\n",
        "    _x = x.view(x.size(0), -1, 8, *x.size()[-2:])\n",
        "    _x = torch.transpose(_x, 1,  2)\n",
        "    _x = _x.reshape(*x.size())\n",
        "    return _x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "255V-NaDeLIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=1, stride=1, padding=0):\n",
        "        super(SNConv, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Conv2d(in_ch, out_ch, kernel, stride, padding))\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdvHzeEdlxFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNDense(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(SNDense, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Linear(in_ch, out_ch))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXQoR6PWcBIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNInceptionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch):\n",
        "        super(SNInceptionBlock, self).__init__()\n",
        "\n",
        "        self.layer_11 = SNConv(in_ch, mid_ch)\n",
        "        self.layer_33 = SNConv(in_ch, mid_ch*2, 3, 1, 1)\n",
        "        self.layer_55 = SNConv(in_ch, mid_ch*2, 5, 1, 2)\n",
        "        self.layer_77 = SNConv(in_ch, mid_ch*3, 7, 1, 3)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        h_11 = self.layer_11(x)\n",
        "        h_33 = self.layer_33(x)\n",
        "        h_55 = self.layer_55(x)\n",
        "        h_77 = self.layer_77(x)\n",
        "        \n",
        "        h = torch.cat((h_11, h_33, h_55, h_77), dim=1)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz5PrYJQex1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SelfAttentionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, gamma=1.):\n",
        "        super(SelfAttentionBlock, self).__init__()\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.cf = SNConv(in_ch, out_ch//8)\n",
        "        self.cg = SNConv(in_ch, out_ch//8)\n",
        "        self.ch = SNConv(in_ch, out_ch)\n",
        "        self.softmax = nn.Softmax(2)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        f = self.cf(x)\n",
        "        g = self.cg(x)\n",
        "        h = self.ch(x)\n",
        "        f = f.view(f.size(0), f.size(1), -1)\n",
        "        g = g.view(g.size(0), g.size(1), -1)\n",
        "        h = h.view(h.size(0), h.size(1), -1)\n",
        "        \n",
        "        attention_map = torch.bmm(torch.transpose(f, 1, 2), g)\n",
        "        attention_map = self.softmax(attention_map)\n",
        "        feature_map = torch.bmm(h, torch.transpose(attention_map, 1, 2))\n",
        "        feature_map = feature_map.view(*x.size())\n",
        "\n",
        "        return x + feature_map*self.gamma\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        self.gamma = gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yv0ZlRisUb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MinibatchDiscrimination(nn.Module):\n",
        "    def __init__(self, kernel, in_ch, kernel_dims, device):\n",
        "        super(MinibatchDiscrimination, self).__init__()\n",
        "        self.device = device\n",
        "        self.kernel = kernel\n",
        "        self.dim = kernel_dims\n",
        "        self.t = spectral_norm(nn.Linear(in_ch, self.kernel*self.dim))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batchsize = x.size(0)\n",
        "        m = self.t(x).view(batchsize, self.kernel, self.dim, 1)\n",
        "        m_T = torch.transpose(m, 0, 3)\n",
        "        m, m_T = torch.broadcast_tensors(m, m_T)\n",
        "        norm = torch.sum(F.l1_loss(m, m_T, reduction='none'), dim=2)\n",
        "\n",
        "        eraser = torch.eye(batchsize, device=self.device).view(batchsize, 1, batchsize).expand(norm.size())\n",
        "        c_b = torch.exp(-(norm + 1e6 * eraser))\n",
        "        o_b = torch.sum(c_b, dim=2)\n",
        "        h = torch.cat((x, o_b), dim=1)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzW6AWqpGp8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, out_ch=2, alpha=0.5, device=None, sa_gamma=1.):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.in_256 = spectral_norm(nn.Conv2d(3, 32, 1, 1, 0))\n",
        "        self.layer_256 = nn.Sequential(\n",
        "            SNInceptionBlock(32, 4),\n",
        "            SNConv(32, 64, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_128 = spectral_norm(nn.Conv2d(3, 64, 1, 1, 0))\n",
        "        self.layer_128 = nn.Sequential(\n",
        "            SNInceptionBlock(64, 8),\n",
        "            SNConv(64, 128, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_64 = spectral_norm(nn.Conv2d(3, 128, 1, 1, 0))\n",
        "        self.layer_64 = nn.Sequential(\n",
        "            SNInceptionBlock(128, 16),\n",
        "            SNConv(128, 256, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_32 = spectral_norm(nn.Conv2d(3, 256, 1, 1, 0))\n",
        "        self.layer_32 = nn.Sequential(\n",
        "            SNInceptionBlock(256, 32),\n",
        "            SNConv(256, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_16 = spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_16 = nn.Sequential(\n",
        "            SNInceptionBlock(512, 64),\n",
        "            SelfAttentionBlock(512, 512, gamma=sa_gamma),\n",
        "            SNConv(512, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_8 =  spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_8 = nn.Sequential(\n",
        "            SNInceptionBlock(512, 64),\n",
        "            SelfAttentionBlock(512, 512, gamma=sa_gamma),\n",
        "            nn.AvgPool2d(8),\n",
        "            nn.Flatten(),\n",
        "            MinibatchDiscrimination(64, 512, 16, device),\n",
        "            SNDense(512+64, out_ch)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, img_size, delta=None):\n",
        "\n",
        "        if img_size >= 256:\n",
        "            h = self.in_256(x)\n",
        "            h = self.layer_256(h)\n",
        "        else:\n",
        "            h = 0\n",
        "        \n",
        "        if img_size >= 128:\n",
        "            _x = F.avg_pool2d(x, img_size//128)\n",
        "            if img_size == 128:\n",
        "                h = h + self.in_128(_x)\n",
        "            elif delta and img_size == 256:\n",
        "                h = delta * h + (1-delta) * self.in_128(_x)\n",
        "            else:\n",
        "                h = self.alpha * h + (1-self.alpha) * self.in_128(_x)\n",
        "            h = self.layer_128(h)\n",
        "        \n",
        "        if img_size >= 64:\n",
        "            _x = F.avg_pool2d(x, img_size//64)\n",
        "            if img_size == 64:\n",
        "                h = h + self.in_64(_x)\n",
        "            elif delta and img_size == 128:\n",
        "                h = delta * h + (1-delta) * self.in_64(_x)\n",
        "            else:\n",
        "                h = self.alpha * h + (1-self.alpha) * self.in_64(_x)\n",
        "            h = self.layer_64(h)\n",
        "        \n",
        "        if img_size >= 32:\n",
        "            _x = F.avg_pool2d(x, img_size//32)\n",
        "            if img_size == 32:\n",
        "                h = h + self.in_32(_x)\n",
        "            elif delta and img_size == 64:\n",
        "                h = delta * h + (1-delta) *  self.in_32(_x)\n",
        "            else:\n",
        "                h = self.alpha * h + (1-self.alpha) * self.in_32(_x)\n",
        "            h = self.layer_32(h)\n",
        "        \n",
        "        if img_size >= 16:\n",
        "            _x = F.avg_pool2d(x, img_size//16)\n",
        "            if img_size == 16:\n",
        "                h = h + self.in_16(_x)\n",
        "            elif delta and img_size == 32:\n",
        "                h = delta * h + (1-delta) * self.in_16(_x)\n",
        "            else:\n",
        "                h = self.alpha * h + (1-self.alpha) * self.in_16(_x)\n",
        "            h = self.layer_16(h)\n",
        "\n",
        "        _x = F.avg_pool2d(x, img_size//8)\n",
        "        if img_size == 8:\n",
        "            h = h + self.in_8(_x)\n",
        "        elif delta and img_size == 16:\n",
        "            h = delta * h + (1-delta) * self.in_8(_x)\n",
        "        else:\n",
        "            h = self.alpha * h + (1-self.alpha) * self.in_8(_x)\n",
        "        h = self.layer_8(h)\n",
        "        return h\n",
        "\n",
        "    def set_gamma(self, gamma, img_size):\n",
        "        if img_size == 8:\n",
        "            self.layer_8[1].set_gamma(gamma)\n",
        "        if img_size == 16:\n",
        "            self.layer_16[1].set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rmDB54OEsrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=1, stride=1, padding=0):\n",
        "        super(Conv, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_ch, out_ch, kernel, stride, padding),\n",
        "            nn.BatchNorm2d(out_ch)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SroXS2jE_v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dense(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(Dense, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGvG1JXPvr7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Affine(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch=64, w_ch=128):\n",
        "        super(Affine, self).__init__()\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            Dense(in_ch, mid_ch),\n",
        "            Dense(mid_ch, mid_ch),\n",
        "            Dense(mid_ch, mid_ch),\n",
        "            Dense(mid_ch, mid_ch),\n",
        "            Dense(mid_ch, mid_ch),\n",
        "            Dense(mid_ch, mid_ch),\n",
        "            Dense(mid_ch, mid_ch),\n",
        "            Dense(mid_ch, w_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KdRypCUwmjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaIN(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(AdaIN, self).__init__()\n",
        "\n",
        "        self.average_convert = Dense(in_ch, out_ch)\n",
        "        self.bias_convert = Dense(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        h = F.instance_norm(x)\n",
        "        a = self.average_convert(w)\n",
        "        a = a.view(*a.size(), 1, 1).expand(*h.size())\n",
        "        b = self.bias_convert(w)\n",
        "        b = b.view(*b.size(), 1, 1).expand(*h.size())\n",
        "        return h * a + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By7GhkDdFG_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "\n",
        "        self.layer_11 = Conv(in_ch, mid_ch)\n",
        "        self.layer_33 = Conv(in_ch, mid_ch*2, 3, 1, 1)\n",
        "        self.layer_55 = Conv(in_ch, mid_ch*2, 5, 1, 2)\n",
        "        self.layer_77 = Conv(in_ch, mid_ch*3, 7, 1, 3)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        h_11 = self.layer_11(x)\n",
        "        h_33 = self.layer_33(x)\n",
        "        h_55 = self.layer_55(x)\n",
        "        h_77 = self.layer_77(x)\n",
        "        \n",
        "        h = torch.cat((h_11, h_33, h_55, h_77), dim=1)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo2Rk_jFc7Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, latent_w):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.ch_1 = in_ch*3//2\n",
        "        self.ch_2 = in_ch*2\n",
        "\n",
        "        self.inception_1 = InceptionBlock(in_ch, in_ch*3//16)\n",
        "        self.adain_1 = AdaIN(latent_w, self.ch_1)\n",
        "\n",
        "        self.inception_2 = InceptionBlock(self.ch_1, in_ch//4)\n",
        "        self.adain_2 = AdaIN(latent_w, self.ch_2)\n",
        "\n",
        "        self.c = Conv(self.ch_2, out_ch)\n",
        "        self.c_out = Conv(self.ch_2, 3)\n",
        "            \n",
        "    def forward(self, x, w1, w2, noise=None):\n",
        "        _h = noise_injection(x, noise) if noise else x\n",
        "        _h = self.inception_1(_h)\n",
        "        _h = layer_shuffle(_h)\n",
        "        h = zeropad(x, self.ch_1)\n",
        "        h = h + _h\n",
        "        h = self.adain_1(h, w1)\n",
        "\n",
        "        _h = noise_injection(h, noise) if noise else h\n",
        "        _h = self.inception_2(_h)\n",
        "        _h = layer_shuffle(_h)\n",
        "        h = zeropad(h, self.ch_2)\n",
        "        h = h + _h\n",
        "        _h = self.adain_2(h, w1)\n",
        "\n",
        "        h = self.c(_h)\n",
        "        out = self.c_out(_h)\n",
        "        return h, out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKEhOWEuFqEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_size, alpha=0.5, noise=None, device=None):\n",
        "        super(Generator, self).__init__()\n",
        "        self.noise = noise\n",
        "        self.device = device\n",
        "        self.alpha = alpha\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "        self.btm = nn.Linear(self.latent_size, 512*8*8)\n",
        "        self.affine = Affine(self.latent_size, self.latent_size, self.latent_size)\n",
        "        \n",
        "        self.res5 = ResBlock(512, 512, self.latent_size)\n",
        "        self.res4 = ResBlock(512, 256, self.latent_size)\n",
        "        self.res3 = ResBlock(256, 128, self.latent_size)\n",
        "        self.res2 = ResBlock(128, 64, self.latent_size)\n",
        "        self.res1 = ResBlock(64, 32, self.latent_size)\n",
        "        self.res0 = ResBlock(32, 16, self.latent_size)\n",
        "\n",
        "        self.upbi = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "    \n",
        "    def forward(self, x, img_size, delta=None):\n",
        "        h = self.affine(x)\n",
        "        h = self.btm(h).view(-1, 512, 8, 8)\n",
        "        w1 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "        w2 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "        h, out = self.res5(h, w1, w2, self.noise)\n",
        "        \n",
        "        if img_size >= 16:\n",
        "            h = self.upbi(h)\n",
        "            w1 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            w2 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            h, _out = self.res4(h, w1, w2, self.noise)\n",
        "            if delta and img_size == 16:\n",
        "                out = (1-delta) * self.upbi(out) + delta * _out\n",
        "            else:\n",
        "                out = (1-self.alpha) * self.upbi(out) + self.alpha * _out\n",
        "        \n",
        "        if img_size >= 32:\n",
        "            h = self.upbi(h)\n",
        "            w1 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            w2 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            h, _out = self.res3(h, w1, w2, self.noise)\n",
        "            if delta and img_size == 32:\n",
        "                out = (1-delta) * self.upbi(out) + delta * _out\n",
        "            else:\n",
        "                out = (1-self.alpha) * self.upbi(out) + self.alpha * _out\n",
        "        \n",
        "        if img_size >= 64:\n",
        "            h = self.upbi(h)\n",
        "            w1 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            w2 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            h, _out = self.res2(h, w1, w2, self.noise)\n",
        "            if delta and img_size == 64:\n",
        "                out = (1-delta) * self.upbi(out) + delta * _out\n",
        "            else:\n",
        "                out = (1-self.alpha) * self.upbi(out) + self.alpha * _out\n",
        "        \n",
        "        if img_size >= 128:\n",
        "            h = self.upbi(h)\n",
        "            w1 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            w2 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            h, _out = self.res1(h, w1, w2, self.noise)\n",
        "            if delta and img_size == 128:\n",
        "                out = (1-delta) * self.upbi(out) + delta * _out\n",
        "            else:\n",
        "                out = (1-self.alpha) * self.upbi(out) + self.alpha * _out\n",
        "        \n",
        "        if img_size >= 256:\n",
        "            h = self.upbi(h)\n",
        "            w1 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            w2 = self.affine(gaussian((x.size(0), self.latent_size)).to(self.device))\n",
        "            h, _out = self.res0(h, w1, w2, self.noise)\n",
        "            if delta and img_size == 256:\n",
        "                out = (1-delta) * self.upbi(out) + delta * _out\n",
        "            else:\n",
        "                out = (1-self.alpha) * self.upbi(out) + self.alpha * _out\n",
        "\n",
        "        return F.tanh(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RvlFlUWVgCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:{}\".format(GPU))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjzxAjvT6VPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    if type(m) in (nn.Linear, nn.Conv2d):\n",
        "        nn.init.xavier_normal_(m.weight, gain=initial_scale)\n",
        "        m.bias.data.fill_(0)\n",
        "    elif type(m) == nn.BatchNorm2d:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOCsFkxT8yAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = Generator(LATENT_SIZE, alpha=SCALEUP_ALPHA, noise=gen_noise, device=device)\n",
        "dis = Discriminator(out_ch=1, alpha=SCALEUP_ALPHA, device=device, sa_gamma=sa_gamma)\n",
        "\n",
        "if load_weight:\n",
        "    gen.load_state_dict(torch.load(OUT+'{}_{}px_{}epoch.pkl'.format(gen_name, *load_weight)))\n",
        "    gen.eval()\n",
        "    dis.load_state_dict(torch.load(OUT+'{}_{}px_{}epoch.pkl'.format(dis_name, *load_weight)))\n",
        "    dis.eval()\n",
        "else:\n",
        "    gen.apply(weights_init)\n",
        "    dis.apply(weights_init)\n",
        "\n",
        "gen.to(device)\n",
        "dis.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh2tOT6nbjxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_gen = optim.Adam(\n",
        "    gen.parameters(),\n",
        "    lr=learning_rate,\n",
        "    betas=(0.5, 0.999),\n",
        "    weight_decay=gen_weight_decay\n",
        "    )\n",
        "opt_dis = optim.Adam(\n",
        "    dis.parameters(),\n",
        "    lr=learning_rate,\n",
        "    betas=(0.5, 0.999),\n",
        "    weight_decay=dis_weight_decay\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWIg15KG17lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_losses = list()\n",
        "dis_losses = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBbx84zdKHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tweet_interval:\n",
        "    auth = tweepy.OAuthHandler(twitter_api_key.CONSUMER_KEY, twitter_api_key.CONSUMER_SECRET)\n",
        "    auth.set_access_token(twitter_api_key.ACCESS_TOKEN_KEY, twitter_api_key.ACCESS_TOKEN_SECRET)\n",
        "    api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvPMnP12KDyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_log(i, epoch, g_loss, d_loss, g_mean, d_real_mean, d_fake_mean):\n",
        "    print('[{}/{}]\\tLoss_D: {:.4f}\\tLoss_G: {:.4f}\\tD(x): {:.4f}\\tD(G(z)): {:.4f}/{:.4f}'.format(\n",
        "        i, epoch, d_loss, g_loss, d_real_mean, d_fake_mean, g_mean\n",
        "    ))\n",
        "    gen_losses.append(g_loss)\n",
        "    dis_losses.append(d_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLOB11ezFNMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_image(gen, img_size, delta, device):\n",
        "    clear_output()\n",
        "    with torch.no_grad():\n",
        "        generated = gen(gaussian((8, LATENT_SIZE)).to(device), img_size, delta).detach().cpu()\n",
        "    generated = np.transpose(np.reshape(generated, (-1, 3, img_size, img_size)), (0, 2, 3, 1))\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "        \n",
        "    for i, img in enumerate(generated):\n",
        "        plt.subplot(2, 4, i+1).axis('off')\n",
        "        plt.subplot(2, 4, i+1).imshow(Image.fromarray(np.uint8((img+1.)/2. *255.)))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZoVZoMey7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_upload(image_array, api):\n",
        "    bin_io = io.BytesIO()\n",
        "    img = Image.fromarray(np.uint8((image_array+1.)/2. *255.))\n",
        "    img = img.resize((256, 256))\n",
        "    img.save(bin_io, format='JPEG')\n",
        "    result = api.media_upload(filename='{}_generated_{}.jpg'.format(target, uuid.uuid4()), file=bin_io)\n",
        "    return result.media_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myBTJoApd-lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def post_image(gen, api, img_size, epoch, delta, device):\n",
        "    with torch.no_grad():\n",
        "        generated = gen(gaussian((4, LATENT_SIZE)).to(device), img_size, delta).detach().cpu()\n",
        "    generated = np.transpose(np.reshape(generated, (-1, 3, img_size, img_size)), (0, 2, 3, 1))\n",
        "\n",
        "    try:\n",
        "        img_ids = [image_upload(img, api) for img in generated]\n",
        "        hash_tags = ['AIでペガサスを作る',\n",
        "                    'epoch: {}'.format(epoch),\n",
        "                    '#makeing{}'.format(target),\n",
        "                    '#nowlearning...',\n",
        "                    '#AI',\n",
        "                    '#人工知能',\n",
        "                    '#DeepLearning',\n",
        "                    '#GAN']\n",
        "\n",
        "        api.update_status(\n",
        "            status='\\n'.join(hash_tags),\n",
        "            media_ids=img_ids\n",
        "            )\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u84LrAZ6Fm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(gen, dis, img_size, epoch):\n",
        "    torch.save(gen.state_dict(), OUT+'{}_{}px_{}epoch.pkl'.format(gen_name, img_size, epoch))\n",
        "    torch.save(dis.state_dict(), OUT+'{}_{}px_{}epoch.pkl'.format(dis_name, img_size, epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyoRMEDz8DUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_result():\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.plot(gen_losses,label=\"G\")\n",
        "    plt.plot(dis_losses,label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2qg08QSICrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def round_dataset(gen, dis, opt_gen, opt_dis, dataloader, img_size, delta, device):\n",
        "    loss_fun = nn.MSELoss()\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        dis.zero_grad()\n",
        "        x_real = data[0].to(device)\n",
        "        b_size = x_real.size(0)\n",
        "        y_real = dis(x_real, img_size, delta).view(-1)\n",
        "        real_loss = loss_fun(y_real, torch.ones(*y_real.size(), device=device))\n",
        "        real_loss.backward()\n",
        "\n",
        "        x_fake = gen(gaussian((b_size, LATENT_SIZE)).to(device), img_size, delta)\n",
        "        y_fake = dis(x_fake.detach(), img_size, delta).view(-1)\n",
        "        fake_loss = loss_fun(y_fake, torch.zeros(*y_fake.size(), device=device))\n",
        "        fake_loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            clip_grad_norm_(dis.parameters(), grad_clip)\n",
        "        dis_loss = real_loss + fake_loss\n",
        "        opt_dis.step()\n",
        "        \n",
        "        gen.zero_grad()\n",
        "        y_gen = dis(x_fake, img_size, delta).view(-1)\n",
        "        gen_loss = loss_fun(y_gen, torch.ones(*y_gen.size(), device=device))\n",
        "        gen_loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            clip_grad_norm_(gen.parameters(), grad_clip)\n",
        "        opt_gen.step()\n",
        "\n",
        "    return gen_loss.item(), dis_loss.item(), y_gen.mean().item(), y_real.mean().item(), y_fake.mean().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZR5sYeZJI9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, device):\n",
        "    for i in range(epoch):\n",
        "        if img_size <= 16 and i <= sa_endpoint:\n",
        "            gamma = sa_gamma*i/sa_endpoint\n",
        "            dis.set_gamma(gamma, img_size)\n",
        "\n",
        "        if i <= sg_endpoint:\n",
        "            delta = SCALEUP_ALPHA*i/sg_endpoint\n",
        "            delta = delta if delta != 0 else 1e-6\n",
        "        else:\n",
        "            delta = None\n",
        "\n",
        "        log = round_dataset(gen, dis, opt_gen, opt_dis, dataloader, img_size, delta, device)\n",
        "\n",
        "        if i % display_interval == 0:\n",
        "            make_image(gen, img_size, delta, device)\n",
        "\n",
        "        if i % log_interval == 0:\n",
        "            report_log(i, epoch, *log)\n",
        "\n",
        "        if tweet_interval and i % tweet_interval == 0:\n",
        "            post_image(gen, api, img_size, i, delta, device)\n",
        "        \n",
        "        if snapshot_interval and i % snapshot_interval == 0:\n",
        "            save_model(gen, dis, img_size, i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5K3OZn2JhGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upscaling(gen, dis, opt_gen, opt_dis, device):\n",
        "    img_size = 8*2**START\n",
        "    for epoch, batch_size in zip(EPOCHS[START:], BATCH_SIZES[START:]):\n",
        "        dataset = dset.ImageFolder(root=dataroot,\n",
        "                                   transform=transforms.Compose([\n",
        "                                                                 transforms.Resize(img_size),\n",
        "                                                                 transforms.CenterCrop(img_size),\n",
        "                                                                 transforms.RandomHorizontalFlip(),\n",
        "                                                                 transforms.ToTensor(),\n",
        "                                                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                                                 ]))\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        train_loop(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, device)\n",
        "        img_size = img_size*2\n",
        "    report_result()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HefwIhPNI4hL",
        "colab_type": "code",
        "outputId": "dccb4528-00fa-4559-8c21-fa23ef02fb57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "upscaling(gen, dis, opt_gen, opt_dis, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[200/1000]\tLoss_D: 0.3905\tLoss_G: 0.3789\tD(x): 0.6580\tD(G(z)): 0.4811/0.4131\n",
            "[210/1000]\tLoss_D: 0.2854\tLoss_G: 0.4110\tD(x): 0.6388\tD(G(z)): 0.3649/0.3701\n",
            "[220/1000]\tLoss_D: 0.3288\tLoss_G: 0.6152\tD(x): 0.4980\tD(G(z)): 0.2329/0.2258\n",
            "[230/1000]\tLoss_D: 0.3370\tLoss_G: 0.5138\tD(x): 0.5497\tD(G(z)): 0.3248/0.2975\n",
            "[240/1000]\tLoss_D: 0.3313\tLoss_G: 0.4366\tD(x): 0.6507\tD(G(z)): 0.4260/0.3530\n",
            "[250/1000]\tLoss_D: 0.3175\tLoss_G: 0.4855\tD(x): 0.5708\tD(G(z)): 0.3311/0.3128\n",
            "[260/1000]\tLoss_D: 0.2824\tLoss_G: 0.6085\tD(x): 0.5577\tD(G(z)): 0.2511/0.2311\n",
            "[270/1000]\tLoss_D: 0.3088\tLoss_G: 0.4355\tD(x): 0.6618\tD(G(z)): 0.4263/0.3469\n",
            "[280/1000]\tLoss_D: 0.3435\tLoss_G: 0.4007\tD(x): 0.5723\tD(G(z)): 0.3618/0.3724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqzasKfBlk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_image(gen, 256, device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}