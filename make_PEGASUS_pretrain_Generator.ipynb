{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of make_PEGASUS_pretrain_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2LONgCSHkKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target\n",
        "target = 'horse'\n",
        "\n",
        "# hyper params\n",
        "iteration = 100000\n",
        "batchsize = 64\n",
        "initial_scale = 1\n",
        "\n",
        "# extension params\n",
        "snapshot_interval = iteration//10\n",
        "display_interval = iteration//100\n",
        "update_interval = display_interval\n",
        "log_interval = iteration//1000\n",
        "tweet_interval = display_interval\n",
        "\n",
        "# model params\n",
        "latent_size = 128\n",
        "sa_gamma = 1.\n",
        "gen_noise = 5e-2\n",
        "sa_endpoint = 50000\n",
        "\n",
        "# learning controller\n",
        "learning_rate = 1e-4\n",
        "grad_clip = None\n",
        "grad_decay = 1e-5\n",
        "load_weight = True\n",
        "load_opt = False\n",
        "load_dis = True\n",
        "save_opt = False\n",
        "save_dis = True\n",
        "IMG_SIZE = 16\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE)\n",
        "GPU = 0\n",
        "\n",
        "# file names\n",
        "mount = './'\n",
        "OUT = '{}/Drive_sync/result/'.format(mount)\n",
        "dataset = '{}/Drive_sync/picture/{}_pic/**/*'.format(mount, target)\n",
        "\n",
        "gen_name = '{}_gen'.format(target)\n",
        "dis_name = '{}_dis'.format(target)\n",
        "\n",
        "opt_gen_name = 'opt_{}_gen'.format(target)\n",
        "opt_horse_dis_name = 'opt_{}_dis'.format(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMVGFtpuE3Mt",
        "colab_type": "code",
        "outputId": "6479e41b-5b29-4da4-9a3e-b95dfbd8014e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import numpy\n",
        "import math\n",
        "import glob\n",
        "import random\n",
        "import io\n",
        "import uuid\n",
        "\n",
        "from PIL import Image, ImageOps, ImageChops, ImageFilter\n",
        "import matplotlib.pyplot as plt\n",
        "import cupy\n",
        "\n",
        "import chainer\n",
        "from chainer import training, backend, Variable\n",
        "from chainer.training import extensions\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import chainer.backends.cuda\n",
        "import chainer.link_hooks as LH\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import tweepy\n",
        "\n",
        "import twitter_api_key"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/hina/anaconda3/envs/colab/lib/python3.7/site-packages/chainer/_environment_check.py:73: UserWarning: \n",
            "--------------------------------------------------------------------------------\n",
            "CuPy (cupy) version 6.0.0 may not be compatible with this version of Chainer.\n",
            "Please consider installing the supported version by running:\n",
            "  $ pip install 'cupy>=6.3.0,<7.0.0'\n",
            "\n",
            "See the following page for more details:\n",
            "  https://docs-cupy.chainer.org/en/latest/install.html\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  requirement=requirement, help=help))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9P2_zkbFjeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_optimizer_Adam(model, alpha=1e-4, beta1=0.5, clip=None, decay=None):\n",
        "    optimizer = chainer.optimizers.Adam(alpha=alpha, beta1=beta1)\n",
        "    optimizer.setup(model)\n",
        "    if clip:\n",
        "        optimizer.add_hook(chainer.optimizer_hooks.GradientClipping(clip))\n",
        "    if decay:\n",
        "        optimizer.add_hook(chainer.optimizer_hooks.WeightDecay(decay))\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGloZh9xEu9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian(size):\n",
        "    return F.gaussian(cupy.zeros(size, dtype=cupy.float32),\n",
        "                     cupy.ones(size, dtype=cupy.float32))\n",
        "    \n",
        "def zeropad(x, ch):\n",
        "    return F.pad(x, ((0, 0), (0, ch-x.shape[1]), (0, 0), (0, 0)), 'constant', constant_values=0)\n",
        "\n",
        "def gap(x):\n",
        "    return F.average_pooling_2d(x, x.shape[-2:])\n",
        "    \n",
        "def noise_injection(x, k):\n",
        "    return F.gaussian(x, instance_var(x)*k)\n",
        "    \n",
        "def instance_var(x):\n",
        "    _shape = x.shape\n",
        "    _x = F.reshape(x, _shape[:2]+(-1,))\n",
        "    _ = F.mean(_x, axis=2, keepdims=True)\n",
        "    _ = (_x - _)**2\n",
        "    _ = F.mean(_, axis=2, keepdims=True)\n",
        "    _ = F.broadcast_to(_[:,:,:,None], _shape)\n",
        "    return _\n",
        "\n",
        "def upsample(x):\n",
        "    return F.depth2space(x, 2)\n",
        "\n",
        "def instance_normalization(x):\n",
        "    _shape = x.shape\n",
        "    x = F.reshape(x, _shape[:2]+(-1,))\n",
        "    x = F.normalize(x, axis=2)\n",
        "    return F.reshape(x, _shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "255V-NaDeLIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv(chainer.Chain):\n",
        "    def __init__(self, ch, kernel=1, stride=1, padding=0, wscale=1.):\n",
        "        super(Conv, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            w = chainer.initializers.HeNormal(wscale)\n",
        "            self.c = L.Convolution2D(None, ch, kernel, stride, padding, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        h = F.leaky_relu(x)\n",
        "        h = self.c(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz5PrYJQex1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SelfAttentionBlock(chainer.Chain):\n",
        "    def __init__(self, ch, wscale=1., gamma=1.):\n",
        "        super(SelfAttentionBlock, self).__init__()\n",
        "\n",
        "        self.gamma = gamma\n",
        "        with self.init_scope():\n",
        "            self.cf = Conv(ch//8, wscale=wscale)\n",
        "            self.cg = Conv(ch//8, wscale=wscale)\n",
        "            self.ch = Conv(ch, wscale=wscale)\n",
        "            \n",
        "    def __call__(self, x):\n",
        "        f = self.cf(x)\n",
        "        g = self.cg(x)\n",
        "        h = self.ch(x)\n",
        "        f = F.reshape(f, f.shape[:2]+(-1,))\n",
        "        g = F.reshape(g, g.shape[:2]+(-1,))\n",
        "        h = F.reshape(h, h.shape[:2]+(-1,))\n",
        "        \n",
        "        attention_map = F.batch_matmul(f, g, transa=True)\n",
        "        attention_map = F.softmax(attention_map, axis=-1)\n",
        "        feature_map = F.batch_matmul(h, attention_map, transb=True)\n",
        "        feature_map = F.reshape(feature_map, x.shape)\n",
        "        return F.add(x, feature_map*self.gamma)\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        self.gamma = gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXQoR6PWcBIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionBlock(chainer.Chain):\n",
        "    def __init__(self, in_ch, out_ch, wscale=1.):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            self.layer_11 = Conv(in_ch, wscale=wscale)\n",
        "            self.layer_33 = Conv(in_ch*2, 3, 1, 1, wscale=wscale)\n",
        "            self.layer_55 = Conv(in_ch*2, 5, 1, 2, wscale=wscale)\n",
        "            self.layer_77 = Conv(in_ch*3, 7, 1, 3, wscale=wscale)\n",
        "\n",
        "            self.c = Conv(out_ch, wscale=wscale)\n",
        "            \n",
        "    def __call__(self, x):\n",
        "        h_11 = self.layer_11(x)\n",
        "        h_33 = self.layer_33(x)\n",
        "        h_55 = self.layer_55(x)\n",
        "        h_77 = self.layer_77(x)\n",
        "        \n",
        "        h = F.concat((h_11, h_33, h_55, h_77))\n",
        "        h = self.c(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdvHzeEdlxFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dense(chainer.Chain):\n",
        "    def __init__(self, ch, wscale=1.):\n",
        "        super(Dense, self).__init__()\n",
        "        \n",
        "        with self.init_scope():\n",
        "            w = chainer.initializers.HeNormal(wscale)\n",
        "            self.l = L.Linear(None, ch, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.leaky_relu(x)\n",
        "        h = self.l(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGvG1JXPvr7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Affine(chainer.Chain):\n",
        "    def __init__(self, mid_ch=64, w_ch=128, wscale=1.):\n",
        "        super(Affine, self).__init__()\n",
        "        \n",
        "        with self.init_scope():\n",
        "            self.l1 = Dense(mid_ch, wscale=wscale)\n",
        "            self.l2 = Dense(mid_ch, wscale=wscale)\n",
        "            self.l3 = Dense(mid_ch, wscale=wscale)\n",
        "            self.l4 = Dense(mid_ch, wscale=wscale)\n",
        "            self.l5 = Dense(mid_ch, wscale=wscale)\n",
        "            self.l6 = Dense(mid_ch, wscale=wscale)\n",
        "            self.l7 = Dense(mid_ch, wscale=wscale)\n",
        "            self.l_out = Dense(w_ch, wscale=wscale)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = self.l1(x)\n",
        "        h = self.l2(h)\n",
        "        h = self.l3(h)\n",
        "        h = self.l4(h)\n",
        "        h = self.l5(h)\n",
        "        h = self.l6(h)\n",
        "        h = self.l7(h)\n",
        "        h = self.l_out(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KdRypCUwmjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaIN(chainer.Chain):\n",
        "    def __init__(self, ch, wscale=1.):\n",
        "        super(AdaIN, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            self.average_convert = Dense(ch, wscale=wscale)\n",
        "            self.bias_convert = Dense(ch, wscale=wscale)\n",
        "\n",
        "    def __call__(self, x, w):\n",
        "        h = instance_normalization(x)\n",
        "        a = self.average_convert(w)\n",
        "        a = F.broadcast_to(F.reshape(a, a.shape+(1, 1)), h.shape)\n",
        "        b = self.bias_convert(w)\n",
        "        b = F.broadcast_to(F.reshape(b, b.shape+(1, 1)), h.shape)\n",
        "        return h * a + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yv0ZlRisUb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MinibatchDiscrimination(chainer.Chain):\n",
        "    def __init__(self, kernel, ch, wscale=1.):\n",
        "        super(MinibatchDiscrimination, self).__init__()\n",
        "        self.kernel = kernel\n",
        "        self.ch = ch\n",
        "        \n",
        "        with self.init_scope():\n",
        "            w = chainer.initializers.HeNormal(wscale)\n",
        "            self.t = L.Linear(None, self.kernel*self.ch, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        m = F.reshape(self.t(x), (batchsize, self.kernel, self.ch))\n",
        "        m = F.expand_dims(m, 3)\n",
        "        m_T = F.transpose(m, (3, 1, 2, 0))\n",
        "        m, m_T = F.broadcast(m, m_T)\n",
        "        norm = F.sum(F.absolute_error(m, m_T), axis=2)\n",
        "        eraser = F.broadcast_to(cupy.eye(batchsize, dtype=cupy.float32).reshape((batchsize, 1, batchsize)), norm.shape)\n",
        "        c_b = F.exp(-(norm + 1e6 * eraser))\n",
        "        o_b = F.sum(c_b, axis=2)\n",
        "        h = F.concat((x, o_b))\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzW6AWqpGp8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(chainer.Chain):\n",
        "\n",
        "    def __init__(self, out_ch=2, k=8, wscale=1., sa_gamma=1.):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        with self.init_scope():\n",
        "            w = chainer.initializers.HeNormal(wscale)\n",
        "            if IMG_SIZE >= 256:\n",
        "                self.c_0 = L.Convolution2D(3, 32, 1, 1, 0, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "                self.inception0 = InceptionBlock(32//k, 32, wscale=wscale)\n",
        "                self.resize1 = Conv(64, 4, 2, 1, wscale=wscale)\n",
        "\n",
        "            if IMG_SIZE >= 128:\n",
        "                self.c_1 = L.Convolution2D(3, 64, 1, 1, 0, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "                self.inception1 = InceptionBlock(64//k, 64, wscale=wscale)\n",
        "                self.resize2 = Conv(128, 4, 2, 1, wscale=wscale)\n",
        "            \n",
        "            if IMG_SIZE >= 64:\n",
        "                self.c_2 = L.Convolution2D(3, 128, 1, 1, 0, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "                self.inception2 = InceptionBlock(128//k, 128, wscale=wscale)\n",
        "                self.resize3 = Conv(256, 4, 2, 1, wscale=wscale)\n",
        "\n",
        "            if IMG_SIZE >= 32:\n",
        "                self.c_3 = L.Convolution2D(3, 256, 1, 1, 0, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "                self.inception3 = InceptionBlock(256//k, 256, wscale=wscale)\n",
        "                self.resize4 = Conv(512, 4, 2, 1, wscale=wscale)\n",
        "\n",
        "            if IMG_SIZE >= 16:\n",
        "                self.c_4 = L.Convolution2D(3, 512, 1, 1, 0, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "                self.inception4 = InceptionBlock(512//k, 512, wscale=wscale)\n",
        "                self.sa4 = SelfAttentionBlock(512, wscale=wscale, gamma=sa_gamma)\n",
        "                self.resize5 = Conv(1024, 4, 2, 1, wscale=wscale)\n",
        "\n",
        "            self.c_5 = L.Convolution2D(3, 1024, 1, 1, 0, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "            self.inception5 = InceptionBlock(1024//k, 1024, wscale=wscale)\n",
        "            self.sa5 = SelfAttentionBlock(1024, wscale=wscale, gamma=sa_gamma)\n",
        "\n",
        "            self.minibatch_discrimination = MinibatchDiscrimination(64, 16, wscale=wscale)\n",
        "\n",
        "            self.l_out = Dense(out_ch, wscale=wscale)\n",
        "    \n",
        "    def __call__(self, x):\n",
        "\n",
        "        if IMG_SIZE >= 256:\n",
        "            h = self.c_0(x)\n",
        "            h = self.inception0(h)\n",
        "            h = self.resize1(h)\n",
        "        else:\n",
        "            h = 0\n",
        "        \n",
        "        if IMG_SIZE >= 128:\n",
        "            h = h + self.c_1(F.average_pooling_2d(x, IMG_SIZE//128))\n",
        "            h = self.inception1(h)\n",
        "            h = self.resize2(h)\n",
        "        \n",
        "        if IMG_SIZE >= 64:\n",
        "            h = h + self.c_2(F.average_pooling_2d(x, IMG_SIZE//64))\n",
        "            h = self.inception2(h)\n",
        "            h = self.resize3(h)\n",
        "        \n",
        "        if IMG_SIZE >= 32:\n",
        "            h = h + self.c_3(F.average_pooling_2d(x, IMG_SIZE//32))\n",
        "            h = self.inception3(h)\n",
        "            h = self.resize4(h)\n",
        "        \n",
        "        if IMG_SIZE >= 16:\n",
        "            h = h + self.c_4(F.average_pooling_2d(x, IMG_SIZE//16))\n",
        "            h = self.inception4(h)\n",
        "            h = self.sa4(h)\n",
        "            h = self.resize5(h)\n",
        "\n",
        "        h = h + self.c_5(F.average_pooling_2d(x, IMG_SIZE//8))\n",
        "        h = self.inception5(h)\n",
        "        h = self.sa5(h)\n",
        "        \n",
        "        h = gap(h)\n",
        "        h = self.minibatch_discrimination(F.reshape(h, (h.shape[0], -1)))\n",
        "        h = self.l_out(h)\n",
        "        return h\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        if IMG_SIZE == 8:\n",
        "            self.sa5.set_gamma(gamma)\n",
        "        if IMG_SIZE == 16:\n",
        "            self.sa4.set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo2Rk_jFc7Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(chainer.Chain):\n",
        "    def __init__(self, ch, k=8, wscale=1.):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.ch = ch\n",
        "        in_ch = self.ch//k\n",
        "\n",
        "        with self.init_scope():\n",
        "            self.inception_1 = InceptionBlock(in_ch, self.ch, wscale=wscale)\n",
        "            self.adain_1 = AdaIN(self.ch, wscale=wscale)\n",
        "\n",
        "            self.inception_2 = InceptionBlock(in_ch*3//2, self.ch*3//2, wscale=wscale)\n",
        "            self.adain_2 = AdaIN(self.ch*3//2, wscale=wscale)\n",
        "\n",
        "            self.c = Conv(3, wscale=wscale)\n",
        "            \n",
        "    def __call__(self, x, w1, w2, noise=None):\n",
        "        _h = noise_injection(x, noise) if noise else x\n",
        "        _h = self.inception_1(_h)\n",
        "        h = zeropad(x, self.ch)\n",
        "        h = h + _h\n",
        "        h = self.adain_1(h, w1)\n",
        "\n",
        "        _h = noise_injection(h, noise) if noise else h\n",
        "        _h = self.inception_2(_h)\n",
        "        h = zeropad(h, self.ch*3//2)\n",
        "        h = h + _h\n",
        "        h = self.adain_2(h, w1)\n",
        "\n",
        "        out = self.c(h)\n",
        "        return h, out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKEhOWEuFqEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(chainer.Chain):\n",
        "\n",
        "    def __init__(self, wscale=1., noise=None):\n",
        "        super(Generator, self).__init__()\n",
        "        self.noise = noise\n",
        "\n",
        "        with self.init_scope():\n",
        "            w = chainer.initializers.HeNormal(wscale)\n",
        "            self.txbtm = L.Linear(None, 1024*8*8, initialW=w).add_hook(LH.SpectralNormalization())\n",
        "            self.affine = Affine()\n",
        "            \n",
        "            self.res5 = ResBlock(1024, wscale=wscale)\n",
        "            if IMG_SIZE >= 16:\n",
        "                self.res4 = ResBlock(512, wscale=wscale)\n",
        "            if IMG_SIZE >= 32:\n",
        "                self.res3 = ResBlock(256, wscale=wscale)\n",
        "            if IMG_SIZE >= 64:\n",
        "                self.res2 = ResBlock(128, wscale=wscale)\n",
        "            if IMG_SIZE >= 128:\n",
        "                self.res1 = ResBlock(64, wscale=wscale)\n",
        "            if IMG_SIZE >= 256:\n",
        "                self.res0 = ResBlock(32, wscale=wscale)\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        \n",
        "        h = F.reshape(self.txbtm(x), (-1, 1024, 8, 8))\n",
        "        w1 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "        w2 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "        h, out = self.res5(h, w1, w2, self.noise)\n",
        "        \n",
        "        if IMG_SIZE >= 16:\n",
        "            h = upsample(h)\n",
        "            w1 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            w2 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            h, _out = self.res4(h, w1, w2, self.noise)\n",
        "            out = F.unpooling_2d(out, 2, cover_all=False) + _out\n",
        "        \n",
        "        if IMG_SIZE >= 32:\n",
        "            h = upsample(h)\n",
        "            w1 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            w2 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            h, _out = self.res3(h, w1, w2, self.noise)\n",
        "            out = F.unpooling_2d(out, 2, cover_all=False) + _out\n",
        "        \n",
        "        if IMG_SIZE >= 64:\n",
        "            h = upsample(h)\n",
        "            w1 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            w2 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            h, _out = self.res2(h, w1, w2, self.noise)\n",
        "            out = F.unpooling_2d(out, 2, cover_all=False) + _out\n",
        "        \n",
        "        if IMG_SIZE >= 128:\n",
        "            h = upsample(h)\n",
        "            w1 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            w2 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            h, _out = self.res1(h, w1, w2, self.noise)\n",
        "            out = F.unpooling_2d(out, 2, cover_all=False) + _out\n",
        "        \n",
        "        if IMG_SIZE >= 256:\n",
        "            h = upsample(h)\n",
        "            w1 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            w2 = self.affine(gaussian((x.shape[0], latent_size)))\n",
        "            h, _out = self.res0(h, w1, w2, self.noise)\n",
        "            out = F.unpooling_2d(out, 2, cover_all=False) + _out\n",
        "\n",
        "        return F.tanh(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUkPjj5gHE76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PretrainUpdater(chainer.training.updaters.StandardUpdater):\n",
        "\n",
        "    def __init__(self, end_point, sa_gamma, *args, **kwargs):\n",
        "        self.end_point = end_point\n",
        "        self.sa_gamma = sa_gamma\n",
        "        self.gen, self.dis = kwargs.pop('models')\n",
        "        super(PretrainUpdater, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        self.dis.set_gamma(gamma)\n",
        "    \n",
        "    def loss_gan(self, model, loss):\n",
        "        chainer.report({'loss': loss}, model)\n",
        "        return loss\n",
        "\n",
        "    def gan_update(self, x_real, gen, dis, gen_optimizer, dis_optimizer):\n",
        "        y_real = dis(x_real)\n",
        "        dis_loss_real = F.mean((y_real-1)**2)\n",
        "\n",
        "        x_fake = gen(gaussian((x_real.shape[0], latent_size)))\n",
        "        y_fake = dis(x_fake)\n",
        "        dis_loss_fake = F.mean((y_fake+1)**2)\n",
        "        dis_optimizer.update(self.loss_gan, dis, (dis_loss_real+dis_loss_fake)*0.5)\n",
        "\n",
        "        gen_loss = F.mean(y_fake**2)\n",
        "        gen_optimizer.update(self.loss_gan, gen, gen_loss)\n",
        "\n",
        "    def update_core(self):\n",
        "        gen_optimizer = self.get_optimizer(gen_name)\n",
        "        dis_optimizer = self.get_optimizer(dis_name)\n",
        "        \n",
        "        if self.iteration <= self.end_point:\n",
        "            gamma = self.sa_gamma*self.iteration/self.end_point\n",
        "            self.set_gamma(gamma)\n",
        "\n",
        "        gen, dis = self.gen, self.dis\n",
        "        target_iter = self.get_iterator('main')\n",
        "\n",
        "        target_batch = target_iter.next()\n",
        "        real_target = Variable(self.converter(target_batch, device=self.device)) /255. *2. -1.\n",
        "        self.gan_update(real_target, gen, dis, gen_optimizer, dis_optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLOB11ezFNMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def out_generated_image(gen):\n",
        "    @chainer.training.make_extension()\n",
        "    def make_image(trainer):\n",
        "        clear_output()\n",
        "        with chainer.using_config('train', False):\n",
        "            generated = gen(F.vstack((cupy.zeros((1, latent_size), dtype=cupy.float32), gaussian((7, latent_size)))))\n",
        "            \n",
        "        generated = F.transpose(F.reshape(generated, (-1, 3)+IMG_SHAPE), (0, 2, 3, 1))\n",
        "        generated = chainer.backends.cuda.to_cpu(generated.array)\n",
        "\n",
        "        plt.figure(figsize=(16, 8))\n",
        "            \n",
        "        for i, img in enumerate(generated):\n",
        "            plt.subplot(2, 4, i+1).axis('off')\n",
        "            plt.subplot(2, 4, i+1).imshow(Image.fromarray(numpy.uint8((img+1.)/2. *255.)))\n",
        "\n",
        "        plt.show()\n",
        "    return make_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZoVZoMey7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_upload(image_array, api):\n",
        "    bin_io = io.BytesIO()\n",
        "    img = Image.fromarray(numpy.uint8((image_array+1.)/2. *255.))\n",
        "    img.save(bin_io, format='JPEG')\n",
        "    result = api.media_upload(filename='{}_generated_{}.jpg'.format(target, uuid.uuid4()), file=bin_io)\n",
        "    return result.media_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myBTJoApd-lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def post_generated_image(gen, api):\n",
        "    @chainer.training.make_extension()\n",
        "    def post_image(trainer):\n",
        "        with chainer.using_config('train', False):\n",
        "            generated = F.unpooling_2d(gen(gaussian((4, latent_size))), 256//IMG_SIZE, cover_all=False)\n",
        "\n",
        "        generated = F.transpose(F.reshape(generated, (-1, 3, 256, 256)), (0, 2, 3, 1))\n",
        "        generated = chainer.backends.cuda.to_cpu(generated.array)\n",
        "\n",
        "        try:\n",
        "            img_ids = [image_upload(img, api) for img in generated]\n",
        "            hash_tags = ['AIでペガサスを作る',\n",
        "                        '#makeing{}'.format(target),\n",
        "                        '#nowlearning...',\n",
        "                        '#AI',\n",
        "                        '#人工知能',\n",
        "                        '#DeepLearning',\n",
        "                        '#GAN']\n",
        "\n",
        "            api.update_status(\n",
        "                status='\\n'.join(hash_tags),\n",
        "                media_ids=img_ids\n",
        "                )\n",
        "        except:\n",
        "            pass\n",
        "    return post_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HzCyp34aACyw",
        "colab": {}
      },
      "source": [
        "gen = Generator(noise=gen_noise, wscale=initial_scale)\n",
        "dis = Discriminator(out_ch=1, sa_gamma=sa_gamma, wscale=initial_scale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT6m896tHwsp",
        "colab_type": "code",
        "outputId": "47fdb24b-b525-4388-8f4a-15b8975894c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chainer.backends.cuda.get_device_from_id(GPU).use()\n",
        "gen.to_gpu()\n",
        "dis.to_gpu()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Discriminator at 0x7fb34eea54d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpCt0JwcZNNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_weight:\n",
        "    chainer.serializers.load_npz(OUT+gen_name+'.npz', gen, strict=False)\n",
        "if load_dis:\n",
        "    chainer.serializers.load_npz(OUT+dis_name+'.npz', dis, strict=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwBvJVx3H8xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_gen = make_optimizer_Adam(\n",
        "    gen,\n",
        "    alpha=learning_rate,\n",
        "    clip=grad_clip,\n",
        "    decay=grad_decay\n",
        "    )\n",
        "opt_dis = make_optimizer_Adam(\n",
        "    dis, \n",
        "    alpha=learning_rate, \n",
        "    clip=grad_clip, \n",
        "    decay=grad_decay\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNdaVJ4gy9mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_opt:\n",
        "    chainer.serializers.load_npz(OUT+opt_gen_name+'.npz', opt_gen, strict=False)\n",
        "if load_opt and load_dis:\n",
        "    chainer.serializers.load_npz(OUT+opt_dis_name+'.npz', opt_dis, strict=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr27raJaIDGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_convert(img_array):\n",
        "    img = Image.fromarray(numpy.uint8(img_array.transpose(1, 2, 0)))\n",
        "    img = img.convert('RGB').resize(IMG_SHAPE)\n",
        "        \n",
        "    if random.random() > 0.5:\n",
        "        img = ImageOps.mirror(img)\n",
        "\n",
        "    img_array = numpy.asarray(img, dtype=numpy.float32).transpose(2, 0, 1)\n",
        "    return img_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xynzSKG4IKYP",
        "colab_type": "code",
        "outputId": "3f786aea-7f55-479f-b3bb-1dd0f93d7c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_files = glob.glob(dataset, recursive=True)\n",
        "print('{} contains {} image files'\n",
        "      .format(dataset, len(target_files)))\n",
        "\n",
        "target_img_dataset = chainer.datasets.ImageDataset(paths=target_files)\n",
        "target_trans_dataset = chainer.datasets.TransformDataset(target_img_dataset, img_convert)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".//Drive_sync/picture/horse_pic/**/* contains 1431 image files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsS_Vf0KIOQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_iter = chainer.iterators.SerialIterator(target_trans_dataset, batchsize, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToPAI31hIQoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "updater = PretrainUpdater(\n",
        "    end_point=sa_endpoint,\n",
        "    sa_gamma=sa_gamma,\n",
        "    models=(gen, dis),\n",
        "    iterator={'main': target_iter},\n",
        "    optimizer={gen_name: opt_gen,\n",
        "               dis_name: opt_dis,},\n",
        "    device=GPU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY5phMAnIWQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = training.Trainer(updater, (iteration, 'iteration'), out=OUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqcOBLPUIaSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "snapshot_interval = (snapshot_interval, 'iteration')\n",
        "display_interval = (display_interval, 'iteration')\n",
        "log_interval = (log_interval, 'iteration')\n",
        "if tweet_interval:\n",
        "    tweet_interval = (tweet_interval, 'iteration')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBbx84zdKHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tweet_interval:\n",
        "    auth = tweepy.OAuthHandler(twitter_api_key.CONSUMER_KEY, twitter_api_key.CONSUMER_SECRET)\n",
        "    auth.set_access_token(twitter_api_key.ACCESS_TOKEN_KEY, twitter_api_key.ACCESS_TOKEN_SECRET)\n",
        "    api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o2TkGb1Icnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.extend(extensions.LogReport(trigger=log_interval))\n",
        "trainer.extend(out_generated_image(gen), trigger=display_interval)\n",
        "trainer.extend(extensions.ProgressBar(update_interval=update_interval))\n",
        "if tweet_interval:\n",
        "    trainer.extend(post_generated_image(gen, api), trigger=tweet_interval)\n",
        "\n",
        "trainer.extend(extensions.snapshot_object(gen, gen_name+'.npz'), trigger=snapshot_interval)\n",
        "\n",
        "if save_dis:\n",
        "    trainer.extend(extensions.snapshot_object(dis, dis_name+'.npz'), trigger=snapshot_interval)\n",
        "\n",
        "if save_opt:\n",
        "    trainer.extend(extensions.snapshot_object(opt_gen, opt_gen_name+'.npz'), trigger=snapshot_interval)\n",
        "\n",
        "if save_dis and save_opt:\n",
        "    trainer.extend(extensions.snapshot_object(opt_dis, opt_dis_name+'.npz'), trigger=snapshot_interval)\n",
        "\n",
        "trainer.extend(extensions.PrintReport([\n",
        "    'epoch', 'iteration', gen_name+'/loss', dis_name+'/loss'\n",
        "    ]), trigger=display_interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HefwIhPNI4hL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}